\documentclass{beamer}

\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{times}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
%\usepackage{lmodern}
% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.
\usepackage{multirow}
\usepackage{color, colortbl}
% \usepackage{cite}
% \usepackage{biblatex}
\usepackage{hyperref}
% \usepackage{caption}

% \DeclareMathSizes{16}{20}{14}{10}

\mode<handout>{\setbeamercolor{background canvas}{bg=black!5}}
\mode<article>{
\topmargin 0.0cm
% \oddsidemargin 0.2cm
%\textwidth 16cm
\textheight 21cm
\footskip 1.0cm

\renewcommand\floatpagefraction{.9}
\renewcommand\topfraction{.9}
\renewcommand\bottomfraction{.9}
\renewcommand\textfraction{.1}
}

\mode<presentation>
{
\setbeamertemplate{navigation symbols}{}
\useinnertheme{rectangles}
\definecolor{UMassRed}{RGB}{150,0,36}
\definecolor{UMassBlack}{RGB}{51, 51, 51}
\definecolor{light-gray}{gray}{0.8}
\definecolor{HopkinsBlue}{RGB}{28,72,130}
\definecolor{HopkinsOlive}{RGB}{132,122,21}

\setbeamercolor{frametitle}{fg=white, bg=UMassRed}
\setbeamercolor{section in head/foot}{fg=white, bg=gray}

\setbeamercolor{title}{fg=UMassRed}
\setbeamertemplate{enumerate items}[default]
\setbeamercolor{enumerate item}{fg=UMassBlack}
\setbeamercolor{section number projected}{bg=black}
\setbeamercolor{section in toc}{fg=UMassRed}
\setbeamercolor{subsection number projected}{bg=UMassRed}
\setbeamercolor{itemize item}{fg=UMassBlack}
\setbeamercolor{itemize subitem}{fg=UMassRed}

\setbeamertemplate{frametitle}
{
\begin{beamercolorbox}[wd=\paperwidth, sep=.01cm] {frametitle}
\begin{minipage}[t]{0.6cm}
\vspace{0pt}
\begin{beamercolorbox}[wd=.6cm] {frametitle}
\end{beamercolorbox}%
\end{minipage}
\begin{minipage}[t]{.9\paperwidth}
\vspace{0pt}
\begin{beamercolorbox}[wd=.85\paperwidth, sep=.2cm] {}
{\Large \insertframetitle}
\par
{\large \insertframesubtitle}
% \vskip5pt
\end{beamercolorbox}
\end{minipage}
\end{beamercolorbox}
}

\setbeamertemplate{footline}
{\leavevmode
\begin{beamercolorbox}[ht=2.5ex,dp=1ex, wd=.85\paperwidth]
{section in head/foot}
\raggedright{\quad \insertsection \qquad
\emph{ \insertsubsection}}
\end{beamercolorbox}%
\begin{beamercolorbox}[ht=2.5ex, dp=1ex,
wd=.15\paperwidth]{section in head/foot}
\raggedleft{\insertframenumber/18 \ }

\end{beamercolorbox}%

}

}

\newenvironment{changemargin}[2]{%
\begin{list}{}{%
\setlength{\topsep}{0pt}%
\setlength{\leftmargin}{#1}%
\setlength{\rightmargin}{#2}%
\setlength{\parindent}{0cm}%
\setlength{\listparindent}{\parindent}%
\setlength{\itemindent}{\parindent}%
\setlength{\parsep}{\parskip}%
}%
\item[]}{\end{list}}

%Allows the insertion of background images
\newcommand\BackgroundPicture[1]{%
\setbeamertemplate{background}{%
\parbox[c][\paperheight]{\paperwidth}{%
\includegraphics[height=1\paperheight]{#1}
\hfill \vfill
}}}

\setbeamertemplate{navigation symbols}{} %get rid of the navigation symbols

\renewcommand{\arraystretch}{1.5}

\newcommand{\as}{\stackrel{a.s.}{\longrightarrow}}

\DeclareFontShape{OT1}{cmtt}{bx}{n}{
<5><6><7><8><9><10><10.95><12><14.4><17.28><20.74><24.88>cmttb10}{}

\setbeamertemplate{bibliography entry title}{}
\setbeamertemplate{bibliography entry location}{}
\setbeamertemplate{bibliography entry note}{}

\newcommand{\etal}{\textit{et al}.}
\newcommand{\etalspace}{\textit{et al}. }
\newcommand{\ie}{\textit{i}.\textit{e}. }
\newcommand{\eg}{\textit{e}.\textit{g}. }

\title{Policy-relevant forecasts \\ of \\ infectious disease incidence}
\author{Stephen A Lauer}
\institute{Reich Lab, Department of Biostatistics and Epidemiology,\\ University of Massachusetts, Amherst}

% \titlegraphic{
% \includegraphics[width=2.5cm]{Umass_logo.png}
% \hspace*{0.75cm}~
% \includegraphics[width=2.5cm]{Thai-MoPH-logo.jpg}
% \hspace*{0.75cm}~
% \includegraphics[height=2.25cm]{JH-logo.jpg}
% }

\date{26 April 2018}

\begin{document}

\begin{frame}[plain]
\titlepage
\only<article>{\maketitle}
\end{frame}

\begin{frame}{Forecasting projects I've worked on}

\begin{itemize}
    \item \textbf{Onset of the influenza season}
    \begin{itemize}
        \item Used an algorithm to find optimal threshold to signal season onset (Reich \etal, 2014)
    \end{itemize}
    \item \textbf{Short-term dengue incidence forecasts}
    \begin{itemize}
        \item Validation and evaluation of retrospective forecasts from a spatio-temporal model (Reich \etal, 2016)
        \item Evaluation of spatio-temporal model in a real-time context (Reich \etal, 2016)
        \item Kernal conditional density estimation for retrospective forecasts (Ray \etal, 2017)
    \end{itemize}
    \item \textbf{Reporting delay modeling}
    \begin{itemize}
        \item Expansion factors to update recent, incomplete counts to improve short-term forecasts (Sakrejda \etal, in progress)
    \end{itemize}
    \item \textbf{General}
    \begin{itemize}
        \item The \texttt{ForecastFramework} package helps researchers build, validate, and evaluate forecasting models
    \end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Lessons learned}

\begin{itemize}
    \item There is no single best model for all situations (\ie disease, forecast target, spatial or temporal scale)
    \begin{itemize}
        \item Simple models can be frustratingly good
        % \item Ensembles can help find best models for a given situation (not presented here)
    \end{itemize}
    \item Overfitting on training data is a huge issue, making forecasts non-generalizable
    \begin{itemize}
        \item Can even occur when cross-validating a model
    \end{itemize}
    \item Evaluation metrics affect both model building and interpretation of results
    \begin{itemize}
        \item And thus should not be taken lightly
    \end{itemize}
    \item Forecasting techniques could be applied more broadly
    \begin{itemize}
        \item For use in estimation or causal inference
    \end{itemize}
\end{itemize}

\end{frame}

\begin{frame}

\centering
{\LARGE
Forecasting annual dengue hemorrhagic fever incidence in Thailand}

\end{frame}

\begin{frame}{Origin story}

\begin{itemize}
    \item Our group started making short-term dengue forecasts for the Thailand Ministry of Public Health (MOPH) in 2013
    \item Every April/May, we go to Bangkok to discuss progress
    \item In 2015, they asked "Is this year going to be big?"
    \item Our short-term forecasts were not accurate that far into the future
\end{itemize}
\textbf{Goal: in April of each year, make ``annual'' forecasts for the rest of the year, given the data we have through March}

\end{frame}

\begin{frame}{Choosing a model}

\begin{enumerate}
    \item Rooted in the epidemiology and biology of dengue
    \item Readily examinable and interpretable
    \begin{itemize}
        \item Results more valid and trustable (for us and MOPH)
        \item Rules out black boxes
    \end{itemize}
    \item Flexible in handling non-linear relationships
    \item Makes accurate forecasts for an actionable outcome
\end{enumerate}

\end{frame}

\begin{frame}{Dengue basics}

\centering
\includegraphics[width=1\linewidth]{figure/mechanism-diagram.pdf}

\end{frame}

\begin{frame}{Dengue basics}

\begin{itemize}
\item Virus spread by \emph{Aedes} mosquitoes, mostly in tropics
\item $\sim$390 million infections every year, most asymptomatic
\item Dengue hemorrhagic fever (DHF) may lead to organ failure and death if untreated
\end{itemize}

\begin{center}
\includegraphics[width=1\textwidth]{figure/dengue-regional-suitability.png}

(Global Dengue Risk, Simmons et al., 2012)
\end{center}

\end{frame}

\begin{frame}{Dengue basics: biology}

\begin{columns}
\begin{column}{0.5\textwidth}
    \begin{itemize}
        \item Four distinct serotypes (strains)
        \item First infections are often asymptomatic
        \item Second infections more likely to result in DHF
        \item Difficult to determine susceptibility
        \item Compartmental model hard to fit, near impossible to forecast from
    \end{itemize}
\end{column}
\begin{column}{0.5\textwidth}
    \begin{center}
    \includegraphics[width=0.9\textwidth]{figure/dengue-serotypes.png}

    Courtesy of Xi Meng
    \end{center}
\end{column}
\end{columns}

\end{frame}

% \begin{frame}{Dengue basics: incidence}
%
% \includegraphics[width=1\linewidth]{figure/mechanism-diagram-incidence.pdf}
%
% \end{frame}
%
% \begin{frame}{Dengue basics: incidence}
%
% \begin{itemize}
%     \item Virus spread by \textit{Aedes} mosquitoes
%     % \item Four distinct serotypes (strains)
%     \item First infections are often asymptomatic
%     \begin{itemize}
%         \item Difficult to estimate total number of infections
%     \end{itemize}
%     \item Second infections are more likely to result in dengue hemorrhagic fever (DHF)
%     \begin{itemize}
%         \item Can be life-threatening if left untreated
%         \item Consistently reported over time by MOPH (since 1968!)
%     \end{itemize}
% \end{itemize}
%
% \end{frame}

% \begin{frame}{Dengue basics: susceptibility}
%
% \includegraphics[width=1\linewidth]{figure/mechanism-diagram-susceptibility.pdf}
%
% \end{frame}


\begin{frame}{DHF in Thailand}

\begin{figure}
\centering
\includegraphics[width=1\linewidth]{figure/dhf-incidence-1}
\end{figure}

\end{frame}


\begin{frame}{DHF spatial distribution}

\includegraphics[width=0.45\paperwidth]{figure/incidence-map-2}
\includegraphics[width=0.45\paperwidth]{figure/incidence-map-3}

\end{frame}

\begin{frame}{DHF predictors}

We aggregated a set of potential drivers of annual DHF incidence:

\begin{itemize}
    \item Early season incidence
    \item Susceptibility (proxy)
    \item Population density
    \item Relative humidity (min, mean, max)
    \item Rainfall (max, total)
    \item Temperature (min, mean, max)
\end{itemize}

These are aggregated across individual months (Jan, Feb, Mar) and over seasonal time frames, for a total of 34 covariates.

\end{frame}

% \begin{frame}{Seasonal time frames}
%
% \includegraphics[width=0.8\paperwidth]{figure/season-timing}
%
% \end{frame}

\section*{Methods}

\begin{frame}{Forecasting model}

We model the incidence, $Y_{it}$, for province $i$ in year $t$ as a generalized additive model of the negative binomial family:

\begin{align*}
    Y_{i,t} &\sim NB(n_{it}\lambda_{it}, r) \\
    \log \Big [ \mathbf{E}(Y_{it}) \Big ] &= \log(n_{it}) + \alpha_i + \sum_{j=1}^J g_j(x_{jit}|\boldsymbol{\theta}) \\
    \alpha_i &\sim Normal(\mu, \sigma^2)
\end{align*}

\begin{itemize}
    \item $n_{it}$ is population, $\lambda_{it}$ is incidence rate, $r$ is NB dispersion
    \item $\alpha_i$ is a random effect for province, $g_j(x_{jit}|\boldsymbol{\theta})$ is a penalized cubic spline for the $j$th covariate
    % \item this model framework account for non-linear relationships between covariates and outcome and can be sampled from to get probabilistic forecasts
\end{itemize}

\end{frame}

\begin{frame}{Cross validation for variable selection}

Want to use splines for flexibility and interpretability, but have too many covariates to fit a full model.
Furthermore, model should be generalizable beyond this data (\ie future years).

\begin{itemize}
    \item Split data into training (2000-09) and testing sets (2010-14)
    \item Conducted leave-one-year-out cross validation with each candidate model across the training phase
    \item Used a forward-backward stepwise algorithm to select a model that minimized the cross-validated mean absolute error (CV MAE)
    \item The model with the lowest CV MAE and the model with the fewest covariates within 1 SD of that model were selected to make forecasts for the testing phase
    \item Final models judged on testing phase performance
\end{itemize}

\end{frame}

\section*{Results}

\begin{frame}{Testing phase models}

\begin{itemize}
    \item The weather-incidence-and-population (WIP) model:
    \begin{itemize}
        \item Pre-season (January-March) incidence
        \item Total January rainfall
        \item Mean January temperature
        \item Mean low-season (November-March) temperature
        \item Provincial population
    \end{itemize}
    \item The incidence-only model
    \item Baseline forecasts:
    \begin{itemize}
        \item 10-year provincial median incidence rate
    \end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{WIP splines}

\begin{figure}
\centering
\includegraphics[width=1\textwidth]{figure/wip-covs-training-1}
\end{figure}

\end{frame}

\begin{frame}{Evaluation methods}

\begin{itemize}
    \item Relative MAE (rMAE):
\end{itemize}
$$\frac{\text{MAE}_\text{model}}{\text{MAE}_\text{baseline}}$$
\begin{itemize}
    \item \% of forecasts better than baseline:
\end{itemize}
$$
\frac{1}{P_k}\sum_{i, t \in k} I(\left \vert \log(\widehat{Y}_{model,i,t})-\log(Y_{i,t})\right \vert < \left \vert \log(\widehat{Y}_{baseline,i,t})-\log(Y_{i,t})\right \vert)
$$
\begin{itemize}
    \item 80\% prediction interval coverage
    \item Outbreak probability
    \begin{itemize}
        \item Outbreak: 2 SD above 10-year median incidence rate
    \end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Model performance}

\begin{table}[H]
\centering
\begin{tabular}{c|c|p{1.75cm}|p{1.6cm}}
    \hline
    Model & rMAE & \% of forecasts better than baseline & 80\% PI coverage \\
    \hline
    WIP & 0.87 & 56.3 & 69.7 \\
    Incidence-only & \textbf{0.81} & \textbf{64.7} & \textbf{80.0} \\
    Baseline & 1.00 &  &  \\
    \hline
\end{tabular}
\end{table}

\centering
(Simple models can be frustratingly good)

\end{frame}

\begin{frame}{CV assessment}

\centering
\includegraphics[width=1\textwidth]{figure/mae-by-covariate-and-validation.png}

(Overfitting is an issue, even with cross validation)
\end{frame}

\begin{frame}{Model performance}

\centering
\includegraphics[height=0.75\paperheight]{figure/rel-mae-maps-moph.png}
% \includegraphics[width=5cm]{figure/spatial-rmae-maps-1}
% \includegraphics[width=5cm]{figure/spatial-rmae-maps-2} \hfill{}

\centering
(No single model works best in all situations)

\end{frame}

\begin{frame}{Outbreak performance}

\begin{figure}
\centering
\includegraphics[width=0.75\linewidth]{figure/roc-plot.png}
\end{figure}

\end{frame}

\section*{Conclusion}

\begin{frame}{Takeaways}

\begin{itemize}
    \item We make annual forecasts for DHF incidence in Thailand; carefully thought out and executed the modeling, cross validation, and evaluation processes
    \item A model based on pre-season incidence consistently outperformed a baseline model based on the 10-year median rate on out-of-sample forecasts
    \item Inclusion of weather covariates did not improve forecasts in majority of geospatial regions
    \begin{itemize}
        \item Model selection may have overfit on features correlated to susceptibility in training phase
    \end{itemize}
    \item This model successfully ordered provinces by outbreak risk, which could be used by public health officials in deciding allocation of resources in the future
    \item Colleagues are working on a mechanistic, annual susceptibility model that could be used in future iterations
\end{itemize}

\end{frame}

\begin{frame}

\centering
{\LARGE Back from the future: using forecasts to infer causality}

\end{frame}

\begin{frame}{The sequel}

\begin{itemize}
    \item We returned to the Thai MOPH in 2017 to deliver annual forecasts and evaluate past predictions
    \item Forecasts for 2016 were too high in some provinces
    \item Several provinces had Zika interventions in 2016
    \item Since Zika and dengue share a vector, reduced dengue incidence (relative to forecasts) may show intervention efficacy
\end{itemize}

\textbf{Goal: use annual forecasts to estimate the effect of an intervention}

\end{frame}

\begin{frame}{Causal inference and estimands}

\begin{itemize}
    \item There is a field of study devoted to this: causal inference
    \item Seek to find the effect of interventions using various estimands
\end{itemize}

$$ \text{Average treatment effect (ATE)} = \mathbb{E}(Y(1) - Y(0)) $$

\begin{itemize}
    \item Where $Y(a)$ is the average outcome $Y$ for all units under treatment $a$
    \item Can't observe both outcomes for each unit, but sometimes estimable, especially in RCTs
\end{itemize}

$$ \text{Average treatment amongst treated (ATT)} = \mathbb{E}(Y(1) - Y(0)|A=1) $$

\begin{itemize}
    \item Same as ATE, but only for the units assigned to treatment group $A=1$
\end{itemize}

\end{frame}

\begin{frame}{Causal estimators}

\begin{align*}
    \text{Unadjusted Estimator} &= \frac{1}{n_1} \sum_{i \in A_i=1} Y_i - \frac{1}{n_0} \sum_{i \in A_i=0} Y_i \\
    &= \frac{1}{N} \sum_i^N \left(\frac{\mathbb{I}(A_i=1)Y_i}{\mathbb{P}(A_i=1)} - \frac{\mathbb{I}(A_i=0)Y_i}{\mathbb{P}(A_i=0)} \right)
\end{align*}

\begin{itemize}
    \item Difference in means between treatment and control groups
    \item Unbiased for ATE in RCTs
\end{itemize}

$$
IPTW = \frac{1}{N} \sum_i^N \left(\frac{\mathbb{I}(A_i=1)Y_i}{\mathbb{P}(A_i=1|W_i)} - \frac{\mathbb{I}(A_i=0)Y_i}{\mathbb{P}(A_i=0|W_i)} \right)
$$

\begin{itemize}
    \item Inverse probability treatment weighting uses propensity score, based on some confounders $W_i$
    \item Unbiased and more efficient when propensity score consistent
\end{itemize}

\end{frame}

\begin{frame}{Covariate adjusted residual estimator (CARE)}

\begin{itemize}
    \item Back to our problem
    \item Hayes and Moulton came up with an estimator based on the difference in model residuals between treatment and control:
\end{itemize}

$$
\text{CARE} = \frac{1}{n_1} \sum_{i \in A_i=1} \left(Y_i - \widehat{Y}_i \right) - \frac{1}{n_0} \sum_{i \in A_i=0} \left(Y_i - \widehat{Y}_i \right)
$$

\begin{itemize}
    \item Important to note that $\widehat{Y}$ does not account for intervention $A$
    \item Concurrently used in ecology, called the ``residual index''
    \item Garcia-Berthou called it ``\textit{ad hoc} with no statistical justification''
\end{itemize}

\end{frame}

\begin{frame}{Covariate adjusted residual estimator (CARE)}

We found some statistical justifications!

\begin{itemize}
    \item By rearranging CARE into:
\end{itemize}

$$
\text{CARE} = \frac{1}{N}\sum_{i=1}^N \left(\frac{\mathbb{I}(A_i = 1)}{\mathbb{P}(A = 1)} - \frac{\mathbb{I}(A_i = 0)}{\mathbb{P}(A = 0)} \right) \left(Y_i - \widehat{Y}_i \right)
$$

\begin{itemize}
    \item In RCTs, asymptotically unbiased
    \item When $\widehat{Y}$ consistent for $Y$, increases efficiency
    \item When $\widehat{Y}$ useless, CARE same as unadjusted estimator
\end{itemize}

\end{frame}


\begin{frame}{CARE--IPW}

By adding inverse probability weighting to CARE, we created our own causal estimator:

$$
\text{CARE--IPW} = \frac{1}{N}\sum_{i=1}^N \left(\frac{\mathbb{I}(A_i = 1)}{\widehat{\mathbb{P}}(A = 1|W_i)} - \frac{\mathbb{I}(A_i = 0)}{\widehat{\mathbb{P}}(A = 0|W_i)} \right) \left(Y_i - \widehat{Y}_i \right)
$$

\begin{itemize}
    \item When $\widehat{\mathbb{P}}(A = 1|W_i)$ consistent for true propensity score, unbiased for ATE, even in observational settings
    \item When $\widehat{Y}$ controls for confounding between $Y$ and $A$, increases efficiency
    \item When $\widehat{Y}$ doesn't, CARE--IPW same as IPTW
\end{itemize}

\end{frame}

\begin{frame}{CARE in forecasting}

\begin{itemize}
    \item Forecasting situation, where there are several time points of observations with an intervention in the final time point
    \item Forecasts are fit on previous time points and predict all observations in final time point without a covariate for the intervention
    \item If $\widehat{Y}$ controls for confounding between $Y$ and $A$, then CARE is unbiased for the ATT
    \item If propensity score is correct, CARE--IPW is unbiased for the ATE
    \item If propensity score is incorrect, but $\widehat{Y}$ controls for confounding, CARE--IPW is unbiased for the ATT
    \item By comparing across estimators, may be able to determine which models are misspecified
\end{itemize}

\end{frame}

\begin{frame}{Coming to a thesis near you!}
\begin{itemize}
    \item Paper with CARE, CARE--IPW proofs, simulations and application to influenza
    \item Paper on application of CARE and CARE--IPW to the effect of Zika interventions on dengue incidence in Thailand
\end{itemize}
\end{frame}

\begin{frame}{Collaborators}

\centering
% \includegraphics[height=1cm]{figure/ImpetusLogo}

% \includegraphics[height=1cm]{figure/reich-lab.png} \hspace*{0.5cm}~ \includegraphics[height=0.75cm]{figure/umass-logo}
\textbf{Reich Lab, UMass Biostats}

Nicholas G Reich, Laura B Balzer, Evan L Ray, and Krzysztof Sakrejda

\vskip5pt
% \includegraphics[height=1cm]{figure/jhu-idd} \hspace*{1cm}~ \includegraphics[height=1.25cm]{figure/JH-logo}
\textbf{Infectious Disease Dynamics, Johns Hopkins Bloomberg School of Public Health}

Justin Lessler, Lindsay T Keegan, and Qifang Bi

\vskip5pt
% \includegraphics[height=1.25cm]{figure/UF-iddynamics}
\textbf{Infectious Disease Dynamics, University of Florida Emerging Pathogens Institute}

Derek AT Cummings

\vskip5pt
% \includegraphics[height=1.5cm]{figure/thai-moph-logo}
\textbf{Bureau of Epidemiology, Department for Disease Control, Ministry of Public Health, Thailand}

Sopon Iamsirithaworn, Paphanij Suangtho, Soawapak Hinjoy, Suthanun Suthachana, and Yongjua Laosiritaworn

\end{frame}

\begin{frame}{Estimated relative susceptibility}

\begin{align*}
    s_{i,t} &= s_{i,t-1} - \frac{y_{i,t-1}}{n_{i,t-1}} + \frac{y_{i,t-3}}{n_{i,t-3}} \\
    s_{i,0} &= \frac{1}{10}\sum_{t=2000}^{2009}\frac{y_{i,t}}{n_{i,t}},
\end{align*}

\begin{itemize}
    \item $s_{it}$ is the estimated relative susceptibility
    \item $y_{it}$ is the observed incidence
    \item $n_{i,t}$ is the population in province $i$ in year $t$
    \item assume each province starts with estimated relative susceptibility of average incidence rate over the training phase ($s_{i,0}$)
    \item provinces with larger susceptible populations are more likely to have greater incidence than provinces with smaller susceptible populations
\end{itemize}

\end{frame}

\begin{frame}{Cross validation for variable selection}

\begin{enumerate}
    \item Start with a null model with only province random effects
    \item Build a new model for each covariate (34 new models), in the following manner
    \begin{enumerate}
        \item If the covariate is not currently in the model, add it
        \item If the covariate is currently in the model, remove it
    \end{enumerate}
    \item Conduct leave-one-season-out cross validation for each new model on the years 2000-2009 and find the cross-validated mean absolute error (CV MAE)
    \item If a new model has a lower CV MAE than any model from the last iteration, keep the new model and repeat steps 2-3. Otherwise, stop.
    \item The model with the lowest CV MAE and the model with the fewest covariates within 1 SD of that model are selected to make forecasts for the testing phase (2010-2014)
\end{enumerate}

\end{frame}

\begin{frame}{WIP splines - testing phase}

\begin{figure}
\centering
\includegraphics[width=1\textwidth]{figure/wip-covs-test-1}
\end{figure}

\end{frame}

\begin{frame}{Model performance}

\begin{figure}
\centering
\includegraphics[width=1\linewidth]{figure/annual-pred-plot-1}
\end{figure}

\end{frame}

\begin{frame}{Outbreak performance}
    \centering
    \includegraphics[height=0.8\paperheight]{figure/outbreak-plot-3}
\end{frame}

\begin{frame}{Outbreak performance}

\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{figure/outbreak-bins-1}
\end{figure}

\end{frame}

\end{document}
