\documentclass{beamer}

\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{times}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
%\usepackage{lmodern}
% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.
\usepackage{multirow}
\usepackage{color, colortbl}
% \usepackage{cite}
% \usepackage{biblatex}
\usepackage{hyperref}
% \usepackage{caption}

% \DeclareMathSizes{16}{20}{14}{10}

\mode<handout>{\setbeamercolor{background canvas}{bg=black!5}}
\mode<article>{
\topmargin 0.0cm
% \oddsidemargin 0.2cm
%\textwidth 16cm
\textheight 21cm
\footskip 1.0cm

\renewcommand\floatpagefraction{.9}
\renewcommand\topfraction{.9}
\renewcommand\bottomfraction{.9}
\renewcommand\textfraction{.1}
}

\mode<presentation>
{
\setbeamertemplate{navigation symbols}{}
\useinnertheme{rectangles}
\definecolor{UMassRed}{RGB}{150,0,36}
\definecolor{UMassBlack}{RGB}{51, 51, 51}
\definecolor{light-gray}{gray}{0.8}
\definecolor{HopkinsBlue}{RGB}{28,72,130}
\definecolor{HopkinsOlive}{RGB}{132,122,21}

\setbeamercolor{frametitle}{fg=white, bg=UMassRed}
\setbeamercolor{section in head/foot}{fg=white, bg=gray}

\setbeamercolor{title}{fg=UMassRed}
\setbeamertemplate{enumerate items}[default]
\setbeamercolor{enumerate item}{fg=UMassBlack}
\setbeamercolor{section number projected}{bg=black}
\setbeamercolor{section in toc}{fg=UMassRed}
\setbeamercolor{subsection number projected}{bg=UMassRed}
\setbeamercolor{itemize item}{fg=UMassBlack}
\setbeamercolor{itemize subitem}{fg=UMassRed}

\setbeamertemplate{frametitle}
{
\begin{beamercolorbox}[wd=\paperwidth, sep=.01cm] {frametitle}
\begin{minipage}[t]{0.6cm}
\vspace{0pt}
\begin{beamercolorbox}[wd=.6cm] {frametitle}
\end{beamercolorbox}%
\end{minipage}
\begin{minipage}[t]{.9\paperwidth}
\vspace{0pt}
\begin{beamercolorbox}[wd=.85\paperwidth, sep=.2cm] {}
{\Large \insertframetitle}
\par
{\large \insertframesubtitle}
% \vskip5pt
\end{beamercolorbox}
\end{minipage}
\end{beamercolorbox}
}

\setbeamertemplate{footline}
{\leavevmode
\begin{beamercolorbox}[ht=2.5ex,dp=1ex, wd=.85\paperwidth]
{section in head/foot}
\raggedright{\quad \insertsection \qquad
\emph{ \insertsubsection}}
\end{beamercolorbox}%
\begin{beamercolorbox}[ht=2.5ex, dp=1ex,
wd=.15\paperwidth]{section in head/foot}
\raggedleft{\insertframenumber/36 \ }

\end{beamercolorbox}%

}

}

\newenvironment{changemargin}[2]{%
\begin{list}{}{%
\setlength{\topsep}{0pt}%
\setlength{\leftmargin}{#1}%
\setlength{\rightmargin}{#2}%
\setlength{\parindent}{0cm}%
\setlength{\listparindent}{\parindent}%
\setlength{\itemindent}{\parindent}%
\setlength{\parsep}{\parskip}%
}%
\item[]}{\end{list}}

%Allows the insertion of background images
\newcommand\BackgroundPicture[1]{%
\setbeamertemplate{background}{%
\parbox[c][\paperheight]{\paperwidth}{%
\includegraphics[height=1\paperheight]{#1}
\hfill \vfill
}}}

\setbeamertemplate{navigation symbols}{} %get rid of the navigation symbols

\renewcommand{\arraystretch}{1.5}

\newcommand{\as}{\stackrel{a.s.}{\longrightarrow}}

\DeclareFontShape{OT1}{cmtt}{bx}{n}{
<5><6><7><8><9><10><10.95><12><14.4><17.28><20.74><24.88>cmttb10}{}

\setbeamertemplate{bibliography entry title}{}
\setbeamertemplate{bibliography entry location}{}
\setbeamertemplate{bibliography entry note}{}

\newcommand{\etal}{\textit{et al}.}
\newcommand{\etalspace}{\textit{et al}. }
\newcommand{\ie}{\textit{i}.\textit{e}. }
\newcommand{\eg}{\textit{e}.\textit{g}. }

\title{Policy-relevant forecasts \\ of \\ infectious disease incidence}
\author{Stephen A Lauer}
\institute{Reich Lab, Department of Biostatistics and Epidemiology,\\ University of Massachusetts, Amherst}

% \titlegraphic{
% \includegraphics[width=2.5cm]{Umass_logo.png}
% \hspace*{0.75cm}~
% \includegraphics[width=2.5cm]{Thai-MoPH-logo.jpg}
% \hspace*{0.75cm}~
% \includegraphics[height=2.25cm]{JH-logo.jpg}
% }

\date{26 April 2018}

\begin{document}

\begin{frame}[plain]
\titlepage
\only<article>{\maketitle}
\end{frame}

\section*{Policy-relevant forecasts, Lauer}
%
% \begin{frame}
%
% \centering
% {\LARGE \textbf {To infinity! (Well, not that far): \\
% Forecasting annual dengue hemorrhagic fever incidence in Thailand}}
%
% \end{frame}

\begin{frame}{Origin story}

\begin{itemize}
    \item Our group started making short-term dengue forecasts for the Thailand Ministry of Public Health (MOPH) in 2013
    \item Every April/May, we go to Bangkok to discuss progress
    \item In 2015, they asked "Is this year going to be big?"
    \item Our short-term forecasts were not accurate that far into the future
\end{itemize}
\textbf{Goal: in April of each year, make ``annual'' forecasts for the rest of the year, given the data we have through March}

\end{frame}

\begin{frame}{Modeling considerations}

\begin{enumerate}
    \item Rooted in the epidemiology and biology of dengue
    \item Easy to examine and interpret
    \item Flexible in handling complex relationships
    \item Will continue to work in future beyond current data
    \item Makes accurate forecasts relative to a baseline model
    \item Results suggest a course of action
\end{enumerate}

\end{frame}

\begin{frame}{Dengue basics}

\centering
\includegraphics[width=1\linewidth]{figure/mechanism-diagram.pdf}

\end{frame}

\begin{frame}{Dengue basics}

\begin{itemize}
\item Virus spread by \emph{Aedes} mosquitoes, mostly in tropics
\item $\sim$390 million infections every year, majority asymptomatic %\cite{Bhatt2013}
\item Dengue hemorrhagic fever (DHF, \emph{aka} ``break bone disease'') is more clinically-relevant and consistently reported over time
\end{itemize}

\begin{center}
\includegraphics[width=1\textwidth]{figure/dengue-regional-suitability.png}

(Global Dengue Risk, Simmons et al., 2012)
\end{center}

\end{frame}

\begin{frame}{Dengue basics: biology}

\begin{columns}
\begin{column}{0.6\textwidth}
    \begin{itemize}
        \item Four distinct serotypes (strains)
        \item Infections may confer immunity to infecting serotype for life, short-term cross-protection to other serotypes
        \item $1^{\text{st}}$ infections asymptomatic
        \item $2^{\text{nd}}$ infections more likely DHF
        \item Near all of 80 compartments unseen
        \item Compartmental model hard to fit, near impossible to forecast from
        \item Difficult to estimate susceptibility
    \end{itemize}
\end{column}
\begin{column}{0.5\textwidth}
    \begin{center}
    \includegraphics[width=0.9\textwidth]{figure/dengue-serotypes.png}

    Courtesy of Xi Meng
    \end{center}
\end{column}
\end{columns}

\end{frame}

% \begin{frame}{Dengue basics: incidence}
%
% \includegraphics[width=1\linewidth]{figure/mechanism-diagram-incidence.pdf}
%
% \end{frame}
%
% \begin{frame}{Dengue basics: incidence}
%
% \begin{itemize}
%     \item Virus spread by \textit{Aedes} mosquitoes
%     % \item Four distinct serotypes (strains)
%     \item First infections are often asymptomatic
%     \begin{itemize}
%         \item Difficult to estimate total number of infections
%     \end{itemize}
%     \item Second infections are more likely to result in dengue hemorrhagic fever (DHF)
%     \begin{itemize}
%         \item Can be life-threatening if left untreated
%         \item Consistently reported over time by MOPH (since 1968!)
%     \end{itemize}
% \end{itemize}
%
% \end{frame}

% \begin{frame}{Dengue basics: susceptibility}
%
% \includegraphics[width=1\linewidth]{figure/mechanism-diagram-susceptibility.pdf}
%
% \end{frame}


\begin{frame}{DHF in Thailand}

\begin{itemize}
    \item Each province and year has at least one outbreak
    \item Intermittent country-wide epidemics
\end{itemize}

\begin{center}
\includegraphics[width=1\textwidth]{figure/dhf-incidence-2}
\end{center}

\end{frame}

\begin{frame}{DHF spatial distribution}

\includegraphics[width=0.45\paperwidth]{figure/incidence-map-2}
\includegraphics[width=0.45\paperwidth]{figure/incidence-map-3}

\end{frame}

\begin{frame}{DHF predictors}

We aggregated a set of potential drivers of annual DHF incidence:

\begin{itemize}
    \item Early season incidence
    \item Susceptibility (proxy)
    \item Population density
    \item Relative humidity (min, mean, max)
    \item Rainfall (max, total)
    \item Temperature (min, mean, max)
\end{itemize}

These are aggregated across individual months (Jan, Feb, Mar) and over seasonal time frames, for a total of 34 covariates.

\end{frame}

% \begin{frame}{Seasonal time frames}
%
% \includegraphics[width=0.8\paperwidth]{figure/season-timing}
%
% \end{frame}

% \section*{Methods}

\begin{frame}{Forecasting model}

We model the incidence, $Y_{it}$, for province $i$ in year $t$ as a generalized additive model of the negative binomial family:

\begin{align*}
    Y_{i,t} &\sim NB(n_{it}\lambda_{it}, r) \\
    \log \Big [ \mathbf{E}(Y_{it}) \Big ] &= \log(n_{it}) + \alpha_i + \sum_{j=1}^J g_j(x_{jit}|\boldsymbol{\theta}) \\
    \alpha_i &\sim Normal(\mu, \sigma^2)
\end{align*}

\begin{itemize}
    \item $n_{it}$ is population, $\lambda_{it}$ is incidence rate, $r$ is NB dispersion
    \item $\alpha_i$ is a random effect for province, $g_j(x_{jit}|\boldsymbol{\theta})$ is a penalized cubic spline for the $j$th covariate
    % \item this model framework account for non-linear relationships between covariates and outcome and can be sampled from to get probabilistic forecasts
\end{itemize}

\end{frame}

\begin{frame}{Cross validation for variable selection}

Cross validation can help us build a model that performs well beyond the available data.
Though we need to be wary of overfitting.

\begin{itemize}
    \item Split data into training (2000-09) and testing sets (2010-14)
    \item Conducted leave-one-year-out cross validation with each candidate model across the training phase
    \item Used a forward-backward stepwise algorithm to select a model that minimized the cross-validated mean absolute error (CV MAE)
    \item The model with the lowest CV MAE and the model with the fewest covariates within 1 SD of that model were selected to make forecasts for the testing phase
    \item Final models judged on testing phase performance
\end{itemize}

\end{frame}

% \section*{Results}

\begin{frame}{Testing phase models}

\begin{itemize}
    \item The weather-incidence-and-population (WIP) model:
    \begin{itemize}
        \item Pre-season (January-March) incidence
        \item Total January rainfall
        \item Mean January temperature
        \item Mean low-season (November-March) temperature
        \item Provincial population
    \end{itemize}
    \item The incidence-only model
    \begin{itemize}
        \item Pre-season incidence
    \end{itemize}
    \item Baseline forecasts:
    \begin{itemize}
        \item 10-year provincial median incidence rate
    \end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{WIP splines}

\begin{figure}
\centering
\includegraphics[width=1\textwidth]{figure/wip-covs-training-1}
\end{figure}

\end{frame}

\begin{frame}{Evaluation methods}

In the testing phase, we made predictive distributions for each province-season (76 provinces across 5 seasons for 380 province-seasons).
The median of the distribution was used as a point forecast.

\begin{itemize}
    \item Relative MAE (rMAE):
\end{itemize}
$$\frac{\text{MAE}_\text{model}}{\text{MAE}_\text{baseline}}$$
\begin{itemize}
    \item \% of forecasts better than baseline
    \begin{itemize}
        \item By being closer to the observed value
    \end{itemize}
    \item 80\% prediction interval coverage
    \item Outbreak probability
    \begin{itemize}
        \item Outbreak: 2 SD above 10-year median incidence rate
        \item Area under the receiver operating curve (AUC)
    \end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Model performance}

\begin{table}[H]
\centering
\begin{tabular}{c|c|p{1.85cm}|p{1.6cm}}
    \hline
    Model & rMAE & \% of forecasts better than baseline & 80\% PI coverage \\
    \hline
    WIP & 0.87 & 56.3 & 69.7 \\
    Incidence-only & \textbf{0.81} & \textbf{64.7} & \textbf{80.0} \\
    Baseline & 1.00 &  &  \\
    \hline
\end{tabular}
\end{table}

% \centering
% (Simple models can be frustratingly good)

\end{frame}

\begin{frame}{CV assessment}

\centering
\includegraphics[width=1\textwidth]{figure/mae-by-covariate-and-validation.png}

% (Overfitting is an issue, even with cross validation)
\end{frame}

\begin{frame}{Model performance}

\centering
\includegraphics[height=0.75\paperheight]{figure/rel-mae-maps-moph.png}
% \includegraphics[width=5cm]{figure/spatial-rmae-maps-1}
% \includegraphics[width=5cm]{figure/spatial-rmae-maps-2} \hfill{}

% \centering
% (No single model works best in all situations)

\end{frame}

\begin{frame}{Outbreak performance}
    \centering
    \includegraphics[height=0.8\paperheight]{figure/outbreak-plot-3}
\end{frame}

\begin{frame}{Outbreak performance}

\begin{figure}
\centering
\includegraphics[width=0.75\linewidth]{figure/roc-plot.png}
\end{figure}

\end{frame}

% \section*{Conclusion}

\begin{frame}{Lessons learned}

\begin{itemize}
    \item<1-> Sometimes the simple model is the best model, though there is no single best model for all situations
    \begin{itemize}
        \item<2-> Pre-season incidence model performed best on out-of-sample forecasts; successfully ordered provinces by outbreak risk
        \item<2-> Model with weather covariates performed better in the north
        % \item Ensembles can help find best models for a given situation (not presented here)
    \end{itemize}
    \item<3-> Overfitting on training data is a huge issue and can occur when using cross validation
    \begin{itemize}
        \item<4-> Model selection may have overfit on features correlated to susceptibility in training phase
        \item<4-> Colleagues are working on a mechanistic annual susceptibility model that could be used in future iterations
    \end{itemize}
    \item<5-> Evaluation metrics affect both model building and interpretation of results
    \begin{itemize}
        \item<5-> And thus should not be taken lightly
    \end{itemize}
    \item<6-> Forecasting techniques could be applied more broadly
    \begin{itemize}
        \item<6-> For use in estimation or causal inference
        \item<7-> See next section!
    \end{itemize}
\end{itemize}

\end{frame}
%
% \begin{frame}{Takeaways}
%
% \begin{itemize}
%     \item We make annual forecasts for DHF incidence in Thailand; carefully thought out and executed the modeling, cross validation, and evaluation processes
%     \item A model based on pre-season incidence consistently outperformed a baseline model based on the 10-year median rate on out-of-sample forecasts
%     \item Inclusion of weather covariates did not improve forecasts in majority of geospatial regions
%     \begin{itemize}
%         \item Model selection may have overfit on features correlated to susceptibility in training phase
%     \end{itemize}
%     \item This model successfully ordered provinces by outbreak risk, which could be used by public health officials in deciding allocation of resources in the future
%     \item Colleagues are working on a mechanistic, annual susceptibility model that could be used in future iterations
% \end{itemize}
%
% \end{frame}

\begin{frame}

\centering
{\LARGE \textbf {Back from the future: \\ Using forecasts to infer causality}}

\end{frame}

\begin{frame}{The sequel}

\begin{itemize}
    \item We returned to the Thai MOPH in 2017 to deliver annual forecasts and evaluate past predictions
    \item Forecasts for 2016 were too high in some provinces
    \item Several provinces had Zika interventions in 2016
    \item Since Zika and dengue share a vector, reduced dengue incidence (relative to forecasts) may show intervention efficacy
\end{itemize}

\textbf{Goal: use annual forecasts to estimate the effect of an intervention}

\end{frame}

\begin{frame}{What is the effect of an intervention?}

\pause

\begin{itemize}
\item<2-> The difference between a unit (\eg person, province) receiving intervention and the \emph{same unit} not receiving intervention
\begin{itemize}
    \item<3-> Unobservable; can't be a control and treatment too
    \item<4-> We'll denote this idea: $Y_i(1)-Y_i(0)$
\end{itemize}
\item<5-> This is why RCTs are the gold standard
\begin{itemize}
    \item<6-> With a large enough sample of two similar groups, we can estimate the average treatment effect by taking the difference in the average between the groups:
\begin{align*}
    \text{Average treatment effect} &= E(Y(1)-Y(0)) \\
    &= E(Y|A=1) - E(Y|A=0)
\end{align*}
    \item<7-> This simple difference in averages is called the ``unadjusted estimator''
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Diagram of an RCT}

\centering
\includegraphics[width=1\textwidth]{figure/dag-intervention-rct}

\end{frame}

\begin{frame}{But we don't have an RCT...}

\pause

\begin{itemize}
    \item<2-> We often give treatment to people who need it, instead of randomly giving treatment to some who need it and some who don't
    \item<2-> In these circumstances, it's easy to imagine that people receiving treatment may have more incidence than people not receiving treatment
    \item<3-> This means that the unadjusted estimator will be biased
\end{itemize}

\end{frame}

\begin{frame}{Observational diagram}

\centering
\includegraphics[width=1\textwidth]{figure/dag-intervention-obs}

\end{frame}

\begin{frame}{What can we do about confounding?}

\pause

\begin{itemize}
    \item<2-> Inverse probability treatment weighting (IPTW)
    \begin{itemize}
        \item<2-> Instead of weighting all observations equally, we weight them by their probability of assignment to treatment or control:
        $$
        \text{IPTW} = \sum_{i \in A=1} \left(\frac{Y_i}{\widehat{\mathbb{P}}(A_i=1|X_i)} \right) - \sum_{i \in A=0} \left(\frac{Y_i}{\widehat{\mathbb{P}}(A_i=0|X_i)} \right)
        $$
        \item<2-> If $\widehat{\mathbb{P}}(A_i=1|X_i)$ is correct, unbiased for average treatment effect; $X_i$ only needs to account for confounding
    \end{itemize}
    \item<3-> Intuitively, we should be able to make a model for $Y$ that controls for confounding to find the effect of an intervention
    \begin{itemize}
    \item<4->
    $$
    \frac{1}{n_1}\sum_{i \in A=1} (Y_i-\widehat{Y}_i) - \frac{1}{n_0}\sum_{i \in A=0} (Y_i-\widehat{Y}_i)
    $$
    \item<4-> If there is a difference in the average residuals between treatment and control, it should suggest that the intervention had an effect
    \end{itemize}
\end{itemize}

\end{frame}

%
% \begin{frame}
%
% $$ \text{Average treatment effect (ATE)} = \mathbb{E}(Y(1) - Y(0)) $$
%
% \begin{itemize}
%     \item Where $Y(a)$ is the average outcome $Y$ for all units under treatment $a$
%     \item Can't observe both outcomes for each unit, but sometimes estimable, especially in RCTs
% \end{itemize}
%
% $$ \text{Average treatment amongst treated (ATT)} = \mathbb{E}(Y(1) - Y(0)|A=1) $$
%
% \begin{itemize}
%     \item Same as ATE, but only for the units assigned to treatment group $A=1$
% \end{itemize}
%
% \end{frame}
%



\begin{frame}{Covariate adjusted residual estimator (CARE)}

\begin{itemize}
    \item Turns out others have thought of this before
    \item Hayes and Moulton called this estimator ``covariate-adjusted residuals'' for use in RCTs at a single point in time (presented without proof)
    \begin{itemize}
        \item $\widehat{Y}$ accounted for confounders, but not for $A$
    \end{itemize}
    \item Concurrently used in ecology, called the ``residual index''
    \item Garcia-Berthou called it ``\textit{ad hoc} with no statistical justification''
\end{itemize}

\end{frame}


\begin{frame}{Covariate adjusted residual estimator (CARE)}

We found some statistical justifications! (Math is in the extra slides)

\begin{itemize}
    \item<2-> In RCTs, CARE is asymptotically unbiased for average treatment effect
    \item<2-> When $\widehat{Y}$ is consistent for $Y$, increases efficiency
    \item<2-> When $\widehat{Y}$ is useless, CARE is same as unadjusted estimator
    \item<3-> Still biased in observational settings though...
\end{itemize}

\end{frame}

\begin{frame}{CARE--IPW}

By adding inverse probability weighting to CARE, we created our own causal estimator:

$$
\text{CARE--IPW} = \sum_{i \in A_i=1} \left(\frac{Y_i - \widehat{Y}_i}{\widehat{\mathbb{P}}(A_i = 1|X_i)} \right) - \sum_{i \in A_i=0} \left(\frac{Y_i - \widehat{Y}_i}{\widehat{\mathbb{P}}(A_i = 0|X_i)} \right)
$$

\begin{itemize}
    \item<2-> When $\widehat{\mathbb{P}}(A_i = a|X_i)$ controls for confounding between $Y$ and $A$, CARE--IPW is unbiased for average treatment effect
    \item<3-> When $\widehat{Y}$ controls for confounding between $Y$ and $A$, increases efficiency
    \item<3-> When $\widehat{Y}$ doesn't, CARE--IPW same as IPTW
    \item<4-> $\widehat{Y}$ doesn't have to include $A$ or be consistent for $Y$!
\end{itemize}

\end{frame}

\begin{frame}{CARE in forecasting}

\begin{itemize}
    \item<1-> Forecasting situation, where there are several time points of observations with an intervention in the final time point
    \item<1-> Model is fit on previous time points and forecasts all observations in final time point without a covariate for the intervention
    \item<2-> If $\widehat{Y}$ controls for confounding between $Y$ and $A$, then CARE unbiased for average treatment amongst the treated (ATT)
    \item<2-> If propensity score is correct, CARE--IPW is unbiased for the average treatment effect
    \item<2-> If propensity score is incorrect, but $\widehat{Y}$ controls for confounding, CARE--IPW is unbiased for the ATT
    \item<3-> Allows us to use more data (from past seasons) to estimate $\widehat{Y}$
    \item<3-> By comparing across estimators, we may be able to determine which models are misspecified
    \item<4-> And perhaps best of all...
\end{itemize}

\end{frame}

\begin{frame}{Causal diagram for thailand}
\centering
\includegraphics[width=1\textwidth]{figure/dag-intervention-zika}

If dengue susceptibility unrelated to Zika incidence, we don't need to account for it!
\end{frame}


\begin{frame}{Coming to a thesis near you!}
\begin{itemize}
    \item Paper with CARE, CARE--IPW proofs, simulations and application to influenza
    \item Paper on application of CARE and CARE--IPW to the effect of Zika interventions on dengue incidence in Thailand
\end{itemize}
\end{frame}

\begin{frame}{Collaborators}

\centering
% \includegraphics[height=1cm]{figure/ImpetusLogo}

% \includegraphics[height=1cm]{figure/reich-lab.png} \hspace*{0.5cm}~ \includegraphics[height=0.75cm]{figure/umass-logo}
\textbf{Reich Lab, UMass Biostats}

Nicholas G Reich, Laura B Balzer, Evan L Ray, and Krzysztof Sakrejda

\vskip5pt
% \includegraphics[height=1cm]{figure/jhu-idd} \hspace*{1cm}~ \includegraphics[height=1.25cm]{figure/JH-logo}
\textbf{Infectious Disease Dynamics, Johns Hopkins Bloomberg School of Public Health}

Justin Lessler, Lindsay T Keegan, and Qifang Bi

\vskip5pt
% \includegraphics[height=1.25cm]{figure/UF-iddynamics}
\textbf{Infectious Disease Dynamics, University of Florida Emerging Pathogens Institute}

Derek AT Cummings

\vskip5pt
% \includegraphics[height=1.5cm]{figure/thai-moph-logo}
\textbf{Bureau of Epidemiology, Department for Disease Control, Ministry of Public Health, Thailand}

Sopon Iamsirithaworn, Paphanij Suangtho, Soawapak Hinjoy, Suthanun Suthachana, and Yongjua Laosiritaworn

\end{frame}


\begin{frame}{Acknowledgements}
This project was funded by NIH NIAID grant 1R01AI102939 and NIGMS R35GM119582.
The findings and conclusions in this manuscript are those of the authors and do not necessarily represent the views of the National Institutes of Health or the National Institute of General Medical Sciences.
The funders had no role in study design, data collection and analysis, decision to present, or preparation of the presentation.
\end{frame}

\begin{frame}

\centering
\textbf{\LARGE Thank you for your \\ time and attention!}

\end{frame}

\begin{frame}{Estimated relative susceptibility}

\begin{align*}
    s_{i,t} &= s_{i,t-1} - \frac{y_{i,t-1}}{n_{i,t-1}} + \frac{y_{i,t-3}}{n_{i,t-3}} \\
    s_{i,0} &= \frac{1}{10}\sum_{t=2000}^{2009}\frac{y_{i,t}}{n_{i,t}},
\end{align*}

\begin{itemize}
    \item $s_{it}$ is the estimated relative susceptibility
    \item $y_{it}$ is the observed incidence
    \item $n_{i,t}$ is the population in province $i$ in year $t$
    \item assume each province starts with estimated relative susceptibility of average incidence rate over the training phase ($s_{i,0}$)
    \item provinces with larger susceptible populations are more likely to have greater incidence than provinces with smaller susceptible populations
\end{itemize}

\end{frame}

\begin{frame}{Cross validation for variable selection}

\begin{enumerate}
    \item Start with a null model with only province random effects
    \item Build a new model for each covariate (34 new models), in the following manner
    \begin{enumerate}
        \item If the covariate is not currently in the model, add it
        \item If the covariate is currently in the model, remove it
    \end{enumerate}
    \item Conduct leave-one-season-out cross validation for each new model on the years 2000-2009 and find the cross-validated mean absolute error (CV MAE)
    \item If a new model has a lower CV MAE than any model from the last iteration, keep the new model and repeat steps 2-3. Otherwise, stop.
    \item The model with the lowest CV MAE and the model with the fewest covariates within 1 SD of that model are selected to make forecasts for the testing phase (2010-2014)
\end{enumerate}

\end{frame}

\begin{frame}{WIP splines - testing phase}

\begin{figure}
\centering
\includegraphics[width=1\textwidth]{figure/wip-covs-test-1}
\end{figure}

\end{frame}

\begin{frame}{Model performance}

\begin{figure}
\centering
\includegraphics[width=1\linewidth]{figure/annual-pred-plot-1}
\end{figure}

\end{frame}

\begin{frame}{Outbreak performance}

\begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{figure/outbreak-bins-1}
\end{figure}

\end{frame}


\begin{frame}{Forecasting projects I've worked on}

\begin{itemize}
    \item \textbf{Onset of the influenza season}
    \begin{itemize}
        \item Used an algorithm to find optimal threshold to signal season onset (Reich \etal, 2014)
    \end{itemize}
    \item \textbf{Short-term dengue incidence forecasts}
    \begin{itemize}
        \item Validation and evaluation of retrospective forecasts from a spatio-temporal model (Reich \etal, 2016)
        \item Evaluation of spatio-temporal model in a real-time context (Reich \etal, 2016)
        \item Kernal conditional density estimation for retrospective forecasts (Ray \etal, 2017)
    \end{itemize}
    \item \textbf{Reporting delay modeling}
    \begin{itemize}
        \item Expansion factors to update recent, incomplete counts to improve short-term forecasts (Sakrejda \etal, in progress)
    \end{itemize}
    \item \textbf{General}
    \begin{itemize}
        \item The \texttt{ForecastFramework} package helps researchers build, validate, and evaluate forecasting models
    \end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{Causal estimators}

\begin{align*}
    \text{Unadjusted Estimator} &= \frac{1}{n_1} \sum_{i \in A_i=1} Y_i - \frac{1}{n_0} \sum_{i \in A_i=0} Y_i \\
    &= \frac{1}{N} \sum_i^N \left(\frac{\mathbb{I}(A_i=1)}{\mathbb{P}(A_i=1)} - \frac{\mathbb{I}(A_i=0)}{\mathbb{P}(A_i=0)} \right) Y_i
\end{align*}

\begin{itemize}
    \item Difference in means between treatment and control groups
    \item Unbiased for ATE in RCTs
\end{itemize}

$$
IPTW = \frac{1}{N} \sum_i^N \left(\frac{\mathbb{I}(A_i=1)}{\mathbb{P}(A_i=1|W_i)} - \frac{\mathbb{I}(A_i=0)}{\mathbb{P}(A_i=0|W_i)} \right) Y_i
$$

\begin{itemize}
    \item Inverse probability treatment weighting uses a propensity score, controlling for confounders, $W$, between $A$ and $Y$
    \item Unbiased and more efficient if propensity score consistent
\end{itemize}

\end{frame}

\begin{frame}{Covariate adjusted residual estimator (CARE)}

We found some statistical justifications!

\begin{itemize}
    \item By rearranging CARE into:
\end{itemize}

$$
\text{CARE} = \frac{1}{N}\sum_{i=1}^N \left(\frac{\mathbb{I}(A_i = 1)}{\mathbb{P}(A = 1)} - \frac{\mathbb{I}(A_i = 0)}{\mathbb{P}(A = 0)} \right) \left(Y_i - \widehat{Y}_i \right)
$$

\begin{itemize}
    \item In RCTs, asymptotically unbiased
    \item When $\widehat{Y}$ consistent for $Y$, increases efficiency
    \item When $\widehat{Y}$ useless, CARE same as unadjusted estimator
\end{itemize}

\end{frame}

\begin{frame}{CARE--IPW}

By adding inverse probability weighting to CARE, we created our own causal estimator:

$$
\text{CARE--IPW} = \frac{1}{N}\sum_{i=1}^N \left(\frac{\mathbb{I}(A_i = 1)}{\widehat{\mathbb{P}}(A_i = 1|W_i)} - \frac{\mathbb{I}(A_i = 0)}{\widehat{\mathbb{P}}(A_i = 0|W_i)} \right) \left(Y_i - \widehat{Y}_i \right)
$$

\begin{itemize}
    \item When $\widehat{\mathbb{P}}(A_i = 1|W_i)$ consistent for true propensity score, unbiased for ATE, even in observational settings
    \item When $\widehat{Y}$ controls for confounding between $Y$ and $A$, increases efficiency
    \item When $\widehat{Y}$ doesn't, CARE--IPW same as IPTW
\end{itemize}

\end{frame}

\end{document}
